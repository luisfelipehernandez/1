{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBWtHTu469Oc6LkEbdac7o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisfelipehernandez/1/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AK26HaQeK9Qh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Descomprimir y listar archivos\n",
        "zip_path = '/content/dress.zip'  # Ruta correcta del archivo ZIP en Google Colab\n",
        "extracted_path = '/content/extracted_dress'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "data_dir = extracted_path\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".jpg\") or file.endswith(\".png\") or file.endswith(\".jpeg\"):\n",
        "            file_paths.append(os.path.join(root, file))\n",
        "            labels.append(root.split('/')[-1])\n",
        "\n",
        "# Preprocesar imágenes y etiquetas\n",
        "images = [img_to_array(load_img(img_path, target_size=(32, 32))) for img_path in file_paths]\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Codificar etiquetas\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "# Dividir en conjunto de entrenamiento y prueba\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Generador de datos con aumento\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Definir el modelo CNN\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo CNN\n",
        "cnn_model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=20, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluar el modelo CNN\n",
        "cnn_loss, cnn_accuracy = cnn_model.evaluate(x_test, y_test)\n",
        "print(f'Precisión del modelo CNN: {cnn_accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2j9sbo0MbGd",
        "outputId": "f4ef402c-c226-4e86-9763-e48f0e449426"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 242ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Precisión del modelo CNN: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Definir el número de clases\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Cargar el modelo VGG16 preentrenado\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Congelar las capas del modelo VGG16\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Añadir capas personalizadas\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Crear el modelo completo\n",
        "model_vgg16 = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model_vgg16.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo VGG16\n",
        "model_vgg16.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=20, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluar el modelo VGG16\n",
        "vgg16_loss, vgg16_accuracy = model_vgg16.evaluate(x_test, y_test)\n",
        "print(f'Precisión del modelo VGG16: {vgg16_accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yA_aGGzsMeDL",
        "outputId": "51b1f908-635e-4f8a-eeac-eec8a5caa2bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3/3 [==============================] - 2s 495ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 1s 377ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 1s 360ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 1s 487ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 1s 481ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 2s 533ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 2s 516ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 1s 370ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 1s 416ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 1s 434ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 1s 477ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 1s 476ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 1s 303ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 1s 491ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 2s 527ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 2s 536ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Precisión del modelo VGG16: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Aplanar las imágenes para el modelo SVM\n",
        "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "# Escalar los datos\n",
        "scaler = StandardScaler()\n",
        "x_train_flat = scaler.fit_transform(x_train_flat)\n",
        "x_test_flat = scaler.transform(x_test_flat)\n",
        "\n",
        "# Verificar la distribución de las etiquetas\n",
        "unique_classes, counts = np.unique(y_train.argmax(axis=1), return_counts=True)\n",
        "print(\"Distribución de las clases en y_train:\", dict(zip(unique_classes, counts)))\n",
        "\n",
        "# Asegurarse de que hay más de una clase en el conjunto de entrenamiento\n",
        "if len(unique_classes) > 1:\n",
        "    # Entrenar el modelo SVM\n",
        "    svm_model = SVC(kernel='linear', probability=True)\n",
        "    svm_model.fit(x_train_flat, y_train.argmax(axis=1))\n",
        "\n",
        "    # Evaluar el modelo SVM\n",
        "    svm_predictions = svm_model.predict(x_test_flat)\n",
        "    svm_accuracy = accuracy_score(y_test.argmax(axis=1), svm_predictions)\n",
        "    print(f'Precisión del modelo SVM: {svm_accuracy:.2f}')\n",
        "\n",
        "    # Reporte de clasificación\n",
        "    print(classification_report(y_test.argmax(axis=1), svm_predictions, target_names=label_encoder.classes_))\n",
        "else:\n",
        "    print(\"El conjunto de entrenamiento no tiene suficientes clases para entrenar un modelo SVM.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA_F71K4Mfxr",
        "outputId": "b51fa3a3-170e-49a2-bf39-049b503c039c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución de las clases en y_train: {0: 71}\n",
            "El conjunto de entrenamiento no tiene suficientes clases para entrenar un modelo SVM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Precisión del modelo CNN: {cnn_accuracy:.2f}')\n",
        "print(f'Precisión del modelo VGG16: {vgg16_accuracy:.2f}')\n",
        "if len(unique_classes) > 1:\n",
        "    print(f'Precisión del modelo SVM: {svm_accuracy:.2f}')\n",
        "else:\n",
        "    print(\"No se pudo entrenar el modelo SVM debido a la falta de clases suficientes en el conjunto de entrenamiento.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkKydYjXMhT7",
        "outputId": "e1efab5b-cc1a-4ddb-9a79-e5dc3ea93661"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo CNN: 1.00\n",
            "Precisión del modelo VGG16: 1.00\n",
            "No se pudo entrenar el modelo SVM debido a la falta de clases suficientes en el conjunto de entrenamiento.\n"
          ]
        }
      ]
    }
  ]
}